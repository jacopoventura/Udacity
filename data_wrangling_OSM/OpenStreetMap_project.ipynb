{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Case Study: Mestre Venice\n",
    "\n",
    "\n",
    "In this project, I apply data munging techniques like assessing data quality for validity, accuracy, completeness, consistency and uniformity, to clean the OpenStreetMap data for my hometown [Venice Mestre, Italy](https://www.openstreetmap.org/node/29997772#map=10/45.4953/12.2415)\n",
    "\n",
    "The following image is a satellite picture of the Venice area taken from Google maps. [Mestre](https://en.wikipedia.org/wiki/Mestre) is part of the city of Venice and it is denoted with the red flag A. \n",
    "![alt text](https://7crooks.files.wordpress.com/2011/04/screen-shot-2011-04-20-at-11-23-56-am.png \"\")\n",
    "\n",
    "The dataset is about **112 MB** and is used entirely in this analysis. \n",
    "\n",
    "In this project, the following information of the dataset are audited:\n",
    "\n",
    "1. street names \n",
    "2. postal code between 30121 and 30176\n",
    "3. names of city suburbs\n",
    "4. province information\n",
    "5. telephone number in the format +39 XXX XXXXXX\n",
    "\n",
    "\n",
    "## PART 1: find errors in the dataset and define functions to correct them\n",
    "\n",
    "In this part of the project, we check the OSM dataset and we check the fields listed in the introduction to find errors. Given the list of errors, functions that correct these error are created and tested.\n",
    "\n",
    "### Street names\n",
    "\n",
    "The XML file of Mestre OpenStreetMap is imported using python's cElementTree. We access the street name using the tags of the XML file. Using Python's regular expression library, we extract street names like raod, avenue, etc, and we compare this name with a list of correct names. If the name is not in the list, we save it in a dictionary of wrong names where the key is the wrong street name and value the list of full wrong names. We create a new dictionary that maps the wrong names (key) to the correct name (value). Using this map, we correct the street names.\n",
    "\n",
    "In this anaylsis, numerous typos error were found (for example, we found Dorsorduro instead of Dorsoduro). Moreover, several names without first capital letter were found. We would like to keep the format with capital letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following errors were found:\n",
      "\n",
      "{'Campazzo': {'Campazzo dei Tolentini'},\n",
      " 'Carbonera': {'Carbonera Corte Nuova'},\n",
      " 'Dorsoduro,': {'Dorsoduro, San Trovaso'},\n",
      " 'Dorsorduro': {'Dorsorduro'},\n",
      " 'Fondamente': {'Fondamente delle Scuole'},\n",
      " 'Forte': {'Forte Marghera'},\n",
      " 'Gallion': {'Gallion'},\n",
      " 'Isola': {'Isola Nuova del Tronchetto'},\n",
      " 'La': {'La Palanca Fondamenta Sant´Eufemia'},\n",
      " 'Lista': {'Lista di Spagna\\n'},\n",
      " 'Sestiere': {'Sestiere Dorsoduro', 'Sestiere Cannaregio'},\n",
      " 'Stazione': {'Stazione Santa Lucia'},\n",
      " 'cannaregio': {'cannaregio'},\n",
      " 'salizada': {'salizada San samuele, san Marco 3358'},\n",
      " 'santa': {'santa croce'},\n",
      " 'via': {'via Gino Allegri', 'via fratelli Bandiera'}}\n",
      "\n",
      "Correction of street names:\n",
      "\n",
      "Sestiere Dorsoduro-->Dorsoduro\n",
      "\n",
      "Sestiere Cannaregio-->Cannaregio\n",
      "\n",
      "Dorsoduro, San Trovaso-->Dorsoduro\n",
      "\n",
      "Gallion-->Calle Gallion\n",
      "\n",
      "Stazione Santa Lucia-->Cannaregio\n",
      "\n",
      "Forte Marghera-->Via Forte Marghera\n",
      "\n",
      "La Palanca Fondamenta Sant´Eufemia-->Fondamenta Sant Eufemia\n",
      "\n",
      "salizada San samuele, san Marco 3358-->Salizada San Samuele\n",
      "\n",
      "Campazzo dei Tolentini-->Campo dei Tolentini\n",
      "\n",
      "cannaregio-->Cannaregio\n",
      "\n",
      "Carbonera Corte Nuova-->Corte Nuova\n",
      "\n",
      "Lista di Spagna\n",
      "-->Rio Terà Lista di Spagna\n",
      "\n",
      "Dorsorduro-->Dorsoduro\n",
      "\n",
      "santa croce-->Santa croce\n",
      "\n",
      "via Gino Allegri-->Via Gino Allegri\n",
      "\n",
      "via fratelli Bandiera-->Via fratelli Bandiera\n",
      "\n",
      "Isola Nuova del Tronchetto-->Isola Nova del Tronchetto\n",
      "\n",
      "Fondamente delle Scuole-->Fondamenta delle Scuole\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "\n",
    "OSMFILE = \"C:/Users/jacopo/Desktop/Deep Learning/Udacity/Projects/DataWrangling/Final project/mestre.osm\"\n",
    "\n",
    "# String pattern for checking street name anomalies\n",
    "street_type_re = re.compile(r'(\\S*)+\\.?', re.I)\n",
    "# +: at least one match of the previous symbol \n",
    "# *: at least 0 match of the previous symbol \n",
    "# ?: 0 or 1 occurrences of the previous symbol\n",
    "\n",
    "\n",
    "#street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "num_line_street_re = re.compile(r'\\d0?(st|nd|rd|th|)\\s(Line)$', re.IGNORECASE) # Spell lines ten and under\n",
    "\n",
    "expected = [\"Via\", \"Corso\", \"Viale\", \"Vicolo\", \"Piazza\",\"Piazzetta\", \n",
    "            \"Piazzale\", \"Calle\",\"Dorsoduro\",\"Rio\",\"Giudecca\",\"Sotoportego\",\n",
    "            \"Campo\",\"Campiello\",\"Fondamenta\",\"Crosera\",\"Salizada\",\"Rotonda\",\n",
    "            \"Riviera\",\"Ponte\",\"Corte\",\"Cannaregio\",\"San\",\"Santa\",\"Piscina\",\"Borgo\"]\n",
    "\n",
    "\n",
    "mapping_street = { \"Campazzo\": \"Campo\",\n",
    "                   \"Dorsorduro\": \"Dorsoduro\",\n",
    "                   \"Fondamente\": \"Fondamenta\",\n",
    "                   \"Gallion\": \"Calle Gallion\",\n",
    "                   \"salizada\": \"Salizada\",\n",
    "                   \"via\": \"Via\",\n",
    "                   \"cannaregio\": \"Cannaregio\",\n",
    "                   \"santa\": \"Santa\",\n",
    "                   \"Sestiere\": \"\",\n",
    "                   \"Carbonera\": \"\",\n",
    "                   \"Forte\": \"Via Forte\"}\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit_street(osmfile):\n",
    "    osm_file = open(osmfile, encoding=\"utf8\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def correct_street_name(name, mapping):\n",
    "    \n",
    "    name_correct = name\n",
    "    \n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type =='Isola':\n",
    "            name_correct = re.sub(\"Nuova\", \"Nova\",name)\n",
    "        elif street_type =='Lista':\n",
    "            name_correct = 'Rio Terà ' + name\n",
    "            name_correct = re.sub(r'(\\n)+', \"\", name_correct)\n",
    "        elif street_type =='Stazione':\n",
    "            name_correct = 'Cannaregio'\n",
    "        elif street_type == 'Dorsoduro,':\n",
    "            name_correct = re.sub(r'(\\,+\\D+)', \"\", name)\n",
    "        elif street_type == 'La':\n",
    "            name_correct = 'Fondamenta Sant Eufemia'\n",
    "        elif street_type in mapping:\n",
    "            name_correct = street_type_re.sub(mapping[street_type], name, count = 1)\n",
    "            \n",
    "            if street_type == 'Sestiere' or street_type == 'Carbonera':\n",
    "                name_correct = re.sub(r'\\s+',\"\", name_correct, count = 1)\n",
    "            elif street_type == 'salizada':\n",
    "                name_correct = re.sub(r'(samuele)+\\D+[0-9]+','Samuele', name_correct, count = 1)\n",
    "\n",
    "    return name_correct\n",
    "\n",
    "\n",
    "\n",
    "# Run codes\n",
    "st_types = audit_street(OSMFILE)\n",
    "print('The following errors were found:\\n')  \n",
    "pprint.pprint(dict(st_types))\n",
    "print()\n",
    "\n",
    "print('Correction of street names:\\n')  \n",
    "for st_type, ways in st_types.items():\n",
    "    for name in ways:\n",
    "        better_name = correct_street_name(name, mapping_street)\n",
    "        print(name + '-->' + better_name)\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postal code\n",
    "\n",
    "We check if the postal code lies between 30121 and 30176. We found that two tags contain the city or street name, whereas several postal codes were outside the expected range. We found that the map of Mestre contains several location outside the city!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following errors in the postal code were found:\n",
      "\n",
      "wrong postal code: 30100\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30020\n",
      "wrong postal code: 30020\n",
      "wrong postal code: 30030\n",
      "wrong postal code: 30030\n",
      "wrong postal code: 30330\n",
      "wrong postal code: 30012\n",
      "wrong postal code: 30030\n",
      "wrong postal code: 30100\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30100\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30100\n",
      "wrong postal code: 30100\n",
      "wrong postal code: 30100\n",
      "wrong postal code: 30100\n",
      "wrong postal code: 30030\n",
      "wrong postal code: 30030\n",
      "wrong postal code: 30030\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30030\n",
      "wrong postal code: 30034\n",
      "wrong postal code: 30034\n",
      "{'PontedeiPugni': {'PontedeiPugni'}, 'Venice30123': {'Venice30123'}}\n",
      "\n",
      "Correction of postal codes:\n",
      "\n",
      "PontedeiPugni-->30123\n",
      "\n",
      "Venice30123-->30123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Audit post code\n",
    "mapping_postal_code = { \"PontedeiPugni\": \"30123\",\n",
    "                        \"Ponte dei Pugni\": \"30123\",\n",
    "                        \"Venice30123\": \"30123\",\n",
    "                        \"Venice 30123\": \"30123\"}\n",
    "\n",
    "\n",
    "POSTCODE = re.compile(r'[A-z]\\d[A-z]\\s?\\d[A-z]\\d')\n",
    "min_code = 30121\n",
    "max_code = 30176\n",
    "def audit_postcode(osmfile):\n",
    "    postal_code_wrong = defaultdict(set)\n",
    "    post_file = open(osmfile, encoding=\"utf8\")\n",
    "    for event, elem in ET.iterparse(post_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'addr:postcode':\n",
    "                    post_code = re.sub(\" \", \"\", tag.attrib['v'].strip())\n",
    "                    m = POSTCODE.match(post_code)\n",
    "                    if m is None:\n",
    "                        aa = [int(s) for s in post_code.split() if s.isdigit()]\n",
    "                        if aa:\n",
    "                            if aa[0]<min_code or aa[0]>max_code:\n",
    "                                #if post_code not in postal_code_wrong:\n",
    "                                print('wrong postal code: %d' %aa[0])\n",
    "                        else:\n",
    "                            #if post_code not in postal_code_wrong:\n",
    "                            postal_code_wrong[post_code].add(post_code)\n",
    "    post_file.close()\n",
    "    return postal_code_wrong\n",
    "\n",
    "def correct_postal_code(name, mapping):\n",
    "    \n",
    "    code_correct = name\n",
    "    \n",
    "    m = re.search(r'(\\D+\\d*)+',name)\n",
    "    if m:\n",
    "        code = m.group()\n",
    "        code_correct = re.sub(r'(\\D+\\d*)+',mapping[code], name, count = 1)\n",
    "        return code_correct\n",
    "    \n",
    "    return code_correct\n",
    "\n",
    "\n",
    "\n",
    "# Run codes\n",
    "print('The following errors in the postal code were found:\\n')  \n",
    "wrong_postal_codes = audit_postcode(OSMFILE)\n",
    "pprint.pprint(dict(wrong_postal_codes))\n",
    "print()\n",
    "print('Correction of postal codes:\\n')  \n",
    "for code_type, ways in wrong_postal_codes.items():\n",
    "    for name in ways:\n",
    "        new_postal_code = correct_postal_code(name, mapping_postal_code)\n",
    "        print(name + '-->' + new_postal_code)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names of city suburbs\n",
    "\n",
    "Here we check if the names of suburbs were correct. Also in this case, we found several locations outside the city. Moreover, we correct missplelled names as in part 1. In two cases, we found the postal code instead of the suburb name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correction of suburb names:\n",
      "\n",
      "Venice-->Venezia\n",
      "\n",
      "Martellago-->Martellago\n",
      "\n",
      "Olmo-->Olmo\n",
      "\n",
      "Marghera VE-->Marghera\n",
      "\n",
      "Mira-->Mira\n",
      "\n",
      "30173-->Tessera\n",
      "\n",
      "3073-->Tessera\n",
      "\n",
      "Spinea-->Spinea\n",
      "\n",
      "Venezia Mestre-->Mestre\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Audit city information\n",
    "\n",
    "mapping_city = {\"Venice\": \"Venezia\",\n",
    "                \"Marghera VE\": \"Marghera\",\n",
    "                \"Venezia Mestre\": \"Mestre\",\n",
    "                \"30173\": \"Tessera\",\n",
    "                \"3073\": \"Tessera\",\n",
    "                \"Martellago\": \"Martellago\",\n",
    "                \"Mira\": \"Mira\",\n",
    "                \"Olmo\": \"Olmo\",\n",
    "                \"Spinea\": \"Spinea\"}\n",
    "\n",
    "expected_suburb = ['Venezia', 'Oriago', 'Mestre', 'Favaro Veneto','Tessera',\n",
    "                   'Marghera', 'Zelarino', 'Campalto', 'Malcontenta','Marcon']\n",
    "\n",
    "def audit_city(osmfile):\n",
    "    suburb_list = defaultdict(set)\n",
    "    city_file = open(osmfile, encoding=\"utf8\")\n",
    "    for event, elem in ET.iterparse(city_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'addr:city':\n",
    "                    city = tag.attrib['v']\n",
    "                    # province = re.sub(\" \", \"\", tag.attrib['v'].strip())\n",
    "                    if city not in expected_suburb:\n",
    "                        suburb_list[city].add(city)\n",
    "                    \n",
    "    city_file.close()\n",
    "    return suburb_list\n",
    "    \n",
    "    \n",
    "def correct_city_sub(name, mapping):\n",
    "    \n",
    "    name_correct = name\n",
    "    \n",
    "    m = re.search(r'(\\D*\\d*)+',name)\n",
    "    if m:\n",
    "        suburb = m.group()\n",
    "        if suburb not in expected_suburb:\n",
    "            name_correct = mapping[suburb]\n",
    "            \n",
    "    return name_correct\n",
    "\n",
    "\n",
    "\n",
    "# Run codes\n",
    "city_sub_wrong = audit_city(OSMFILE)\n",
    "print()\n",
    "print('Correction of suburb names:\\n')  \n",
    "for code_type, ways in city_sub_wrong.items():\n",
    "    for name in ways:\n",
    "        new_suburb = correct_city_sub(name, mapping_city)\n",
    "        print(name + '-->' + new_suburb)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Province information\n",
    "\n",
    "We make sure that province is \"Venezia\" in every node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Venezia']\n"
     ]
    }
   ],
   "source": [
    "# Audit province information\n",
    "def correct_province(name):\n",
    "    \n",
    "    if name=='VE':\n",
    "        name = 'Venezia'\n",
    "        \n",
    "    return name\n",
    "\n",
    "\n",
    "    \n",
    "def audit_province(osmfile):\n",
    "    province_list = []\n",
    "    province_file = open(osmfile, encoding=\"utf8\")\n",
    "    for event, elem in ET.iterparse(province_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'addr:province':\n",
    "                    province = correct_province(re.sub(\" \", \"\", tag.attrib['v'].strip()))\n",
    "                    if province not in province_list:\n",
    "                        province_list.append(province)\n",
    "                    \n",
    "                    \n",
    "    province_file.close()\n",
    "    print(province_list)\n",
    "    \n",
    "audit_province(OSMFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telephone number\n",
    "\n",
    "We check telephone numbers. Using the same approach as part 1, we ensures that all the phone numbers have the same format +39 XXX XXXXX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected phone numbers (first 10):\n",
      "\n",
      "+39 041 715359\n",
      "+39 041 2750218\n",
      "+39 041 5244332\n",
      "+39 041 2776142\n",
      "+39 041 5351288\n",
      "+39 041 2749227\n",
      "+39 041 721901\n",
      "+39 041 5240016\n",
      "+39 041 5442945\n",
      "+39 041 8221044\n",
      "+39 041 5239825\n"
     ]
    }
   ],
   "source": [
    "# Audit phone number    \n",
    "PHONENUM = re.compile(r'\\+39\\s\\d{3}\\s\\d{6,7}')\n",
    "\n",
    "def correct_phone_num(phone_num):\n",
    "\n",
    "    # Check for valid phone number format\n",
    "    m = PHONENUM.match(phone_num)\n",
    "    if m is None:\n",
    "        \n",
    "        # remove postal code \n",
    "        if re.match(r'\\d{5}', phone_num) is not None:\n",
    "            if re.match(r'\\d{6}', phone_num) is None:\n",
    "                return None\n",
    "        \n",
    "        # Convert all dashes to spaces\n",
    "        if \"-\" in phone_num:\n",
    "            phone_num = re.sub(\"-\", \" \", phone_num)\n",
    "         \n",
    "        # remove space between + and 39\n",
    "        if re.match(r'\\+ 3',phone_num[:3]) is not None:\n",
    "            phone_num = re.sub(\" \", \"\", phone_num, count=1)\n",
    "            \n",
    "        # Substitute 00 with +\n",
    "        if phone_num[:2]=='00':\n",
    "            phone_num = '+' + phone_num[2:]\n",
    "            \n",
    "        # Add coutry code\n",
    "        if re.match(r'\\+39|39',phone_num) is None:\n",
    "            phone_num = \"+39\" + phone_num\n",
    "            \n",
    "        # Remove whitespaces\n",
    "        if \" \" in phone_num:\n",
    "            phone_num = re.sub(\" \", \"\", phone_num)\n",
    "            \n",
    "        # Add + in country code\n",
    "        if re.match(r'39\\d{3,}', phone_num) is not None:\n",
    "            phone_num = \"+\" + phone_num\n",
    "            \n",
    "        # Check number in the 4th position\n",
    "        if phone_num[3]=='4':\n",
    "            phone_num = phone_num[:3]+'0'+phone_num[3:]\n",
    "            \n",
    "        if phone_num[3:5]=='03':\n",
    "            phone_num = phone_num[:3]+phone_num[5:]\n",
    "            \n",
    "      \n",
    "        # Space phone number\n",
    "        phone_num = phone_num[:3] + \" \" + phone_num[3:6] + \" \" + phone_num[6:]\n",
    "\n",
    "    return phone_num\n",
    "\n",
    "\n",
    "def audit_phone(osmfile):\n",
    "    phone_list = []\n",
    "    phone_file = open(osmfile, encoding=\"utf8\")\n",
    "    counter = 0\n",
    "    counter_max = 10\n",
    "    for event, elem in ET.iterparse(phone_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'phone':\n",
    "                    phone_num = tag.attrib['v']\n",
    "                    # province = re.sub(\" \", \"\", tag.attrib['v'].strip())\n",
    "                    new_phone = correct_phone_num(phone_num)\n",
    "                    if counter<=counter_max:     \n",
    "                        print(new_phone)\n",
    "                    counter = counter + 1\n",
    "                   # if phone_num not in phone_list:\n",
    "                    #    phone_list.append(phone_num)\n",
    "                    \n",
    "    phone_file.close()\n",
    "    \n",
    "    \n",
    "print('Corrected phone numbers (first 10):\\n')  \n",
    "audit_phone(OSMFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: prepare the data to be inserted into a SQL database\n",
    "\n",
    "The OSM dataset is now parsed and saved as a set of dictionaries, being \"node\" and \"way\".\n",
    "Each element of the OSM XML file is analyzed and corrected using the functions defined in step 1. The document is transformed to tabular format using python's dictionaries and saved into .csv files. These csv files can then easily be imported to a SQL database as tables.\n",
    "This process consists of the following steps:\n",
    "- iteratively step through each top level element in the OSM XML \n",
    "- analyze each node by correcting wrong values and saving them into dictionaries\n",
    "- use a schema and validation library to ensure the transformed data is in the correct format\n",
    "- write each data structure to the appropriate .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "After auditing is complete the next step is to prepare the data to be inserted into a SQL database.\n",
    "To do so you will parse the elements in the OSM XML file, transforming them from document format to\n",
    "tabular format, thus making it possible to write to .csv files.  These csv files can then easily be\n",
    "imported to a SQL database as tables.\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Utilize a schema and validation library to ensure the transformed data is in the correct format\n",
    "- Write each data structure to the appropriate .csv files\n",
    "\n",
    "## Shape Element Function\n",
    "The function should take as input an iterparse Element object and return a dictionary.\n",
    "\n",
    "### If the element top level tag is \"node\":\n",
    "The dictionary returned should have the format {\"node\": .., \"node_tags\": ...}\n",
    "The \"node\" field should hold a dictionary of the following top level node attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- lat\n",
    "- lon\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "The \"node_tags\" field should hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "fields from the secondary tag attributes:\n",
    "- id: the top level node id attribute value\n",
    "- key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "- value: the tag \"v\" attribute value\n",
    "- type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon\n",
    "        is not present.\n",
    "Additionally,\n",
    "- if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "- if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type\n",
    "  and characters after the \":\" should be set as the tag key\n",
    "- if there are additional \":\" in the \"k\" value they and they should be ignored and kept as part of\n",
    "  the tag key. For example:\n",
    "  <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "  should be turned into\n",
    "  {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "- If a node has no secondary tags then the \"node_tags\" field should just contain an empty list.\n",
    "The final return value for a \"node\" element should look something like:\n",
    "{'node': {'id': 757860928,\n",
    "          'user': 'uboot',\n",
    "          'uid': 26299,\n",
    "       'version': '2',\n",
    "          'lat': 41.9747374,\n",
    "          'lon': -87.6920102,\n",
    "          'timestamp': '2010-07-22T16:16:51Z',\n",
    "      'changeset': 5288876},\n",
    " 'node_tags': [{'id': 757860928,\n",
    "                'key': 'amenity',\n",
    "                'value': 'fast_food',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'cuisine',\n",
    "                'value': 'sausage',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'name',\n",
    "                'value': \"Shelly's Tasty Freeze\",\n",
    "                'type': 'regular'}]}\n",
    "                \n",
    "### If the element top level tag is \"way\":\n",
    "The dictionary should have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "The \"way\" field should hold a dictionary of the following top level way attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "The \"way_tags\" field should again hold a list of dictionaries, following the exact same rules as\n",
    "for \"node_tags\".\n",
    "Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" should hold a list of\n",
    "dictionaries, one for each nd child tag.  Each dictionary should have the fields:\n",
    "- id: the top level element (way) id\n",
    "- node_id: the ref attribute value of the nd tag\n",
    "- position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within\n",
    "            the way element\n",
    "The final return value for a \"way\" element should look something like:\n",
    "{'way': {'id': 209809850,\n",
    "         'user': 'chicago-buildings',\n",
    "         'uid': 674454,\n",
    "         'version': '1',\n",
    "         'timestamp': '2013-03-13T15:58:04Z',\n",
    "         'changeset': 15353317},\n",
    " 'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "               {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "               {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "               {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "               {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "               {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "               {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    " 'way_tags': [{'id': 209809850,\n",
    "               'key': 'housenumber',\n",
    "               'type': 'addr',\n",
    "               'value': '1412'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street',\n",
    "               'type': 'addr',\n",
    "               'value': 'West Lexington St.'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:name',\n",
    "               'type': 'addr',\n",
    "               'value': 'Lexington'},\n",
    "              {'id': '209809850',\n",
    "               'key': 'street:prefix',\n",
    "               'type': 'addr',\n",
    "               'value': 'West'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:type',\n",
    "               'type': 'addr',\n",
    "               'value': 'Street'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building',\n",
    "               'type': 'regular',\n",
    "               'value': 'yes'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'levels',\n",
    "               'type': 'building',\n",
    "               'value': '1'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building_id',\n",
    "               'type': 'chicago',\n",
    "               'value': '366409'}]}\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "\n",
    "import schema\n",
    "\n",
    "# from audit import correct_name, is_street_name\n",
    "\n",
    "OSM_PATH = OSMFILE\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "PHONENUM = re.compile(r'\\+1\\s\\d{3}\\s\\d{3}\\s\\d{4}')\n",
    "POSTCODE = re.compile(r'[A-z]\\d[A-z]\\s?\\d[A-z]\\d')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to analyze secondary tags. This analysis is the same for node and way (primary) tags\n",
    "def analyze_subtag(element, second_tag):\n",
    "    \n",
    "    # create dictionary for the secondary tag\n",
    "    dict_second_tag = {}\n",
    "    \n",
    "    # if a secondary tag is present, it is parsed\n",
    "    if second_tag is not None:\n",
    "        dict_second_tag['id'] = element.attrib['id']\n",
    "\n",
    "        # check is column is present\n",
    "        if \":\" not in second_tag.attrib['k']:\n",
    "\n",
    "            # no column\n",
    "            dict_second_tag['key'] = second_tag.attrib['k']\n",
    "            dict_second_tag['value'] = second_tag.attrib['v']\n",
    "            dict_second_tag['type'] = 'regular'\n",
    "        else:\n",
    "\n",
    "            # column found\n",
    "            column_separator_position = second_tag.attrib['k'].index(':')\n",
    "            dict_second_tag['key'] = second_tag.attrib['k'][(column_separator_position+1):]\n",
    "            dict_second_tag['type'] = second_tag.attrib['k'][:column_separator_position]\n",
    "\n",
    "            \n",
    "        ### Find and correct problems in the values of the OSM map data        \n",
    "        # correct street name\n",
    "        if dict_second_tag['key'] == \"street\":\n",
    "            dict_second_tag['value'] = correct_street_name(second_tag.attrib['v'],mapping_street)\n",
    "    \n",
    "        # correct postal code\n",
    "        elif dict_second_tag['key'] == 'postcode':\n",
    "            dict_second_tag['value'] = correct_postal_code(second_tag.attrib['v'], mapping_postal_code)\n",
    "            \n",
    "        # correct suburb name\n",
    "        elif dict_second_tag['key'] == 'city':\n",
    "            dict_second_tag['value'] = correct_city_sub(second_tag.attrib['v'],mapping_city)\n",
    "    \n",
    "        # correct phone number\n",
    "        elif dict_second_tag['key'] == 'phone':\n",
    "            dict_second_tag['value'] = correct_phone_num(second_tag.attrib['v'])\n",
    "            if dict_second_tag['value'] is None:\n",
    "                return None\n",
    "            \n",
    "    \n",
    "        # correct province \n",
    "        elif dict_second_tag['key'] == 'province':\n",
    "            dict_second_tag['value'] = correct_province(second_tag.attrib['v'])\n",
    "\n",
    "        else:\n",
    "            dict_second_tag['value'] = second_tag.attrib['v']\n",
    "\n",
    "    return dict_second_tag\n",
    "    \n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    node_dict = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        # analyze primary tag\n",
    "        for attrib in element.attrib.items():\n",
    "            node_attribs[attrib[0]] = attrib[1]\n",
    "            \n",
    "        # check secondary tags\n",
    "        for secondary_tag in element.iter():\n",
    "            if secondary_tag.tag == 'tag':\n",
    "                dict_subtag = analyze_subtag(element, secondary_tag)\n",
    "                if dict_subtag is not None:\n",
    "                    tags.append(dict_subtag)\n",
    "                    \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "         \n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for attrib in element.attrib.items():\n",
    "            way_attribs[attrib[0]] = attrib[1]\n",
    "            \n",
    "        # check secondary tags\n",
    "        counter = 0\n",
    "        for secondary_tag in element.iter():\n",
    "            if secondary_tag.tag == 'tag':\n",
    "                dict_subtag = analyze_subtag(element, secondary_tag)\n",
    "                if dict_subtag is not None:\n",
    "                    tags.append(dict_subtag)\n",
    "                    \n",
    "            elif secondary_tag.tag == 'nd':\n",
    "                dict_subtag_nd = {}\n",
    "                dict_subtag_nd['id'] = element.attrib['id']\n",
    "                dict_subtag_nd['node_id'] = secondary_tag.attrib['ref']\n",
    "                dict_subtag_nd['position'] = counter\n",
    "                counter = counter + 1\n",
    "                way_nodes.append(dict_subtag_nd)\n",
    "  \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    \n",
    "    \n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        print()\n",
    "        print(element)\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.items()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, str) else v) for k, v in row.items()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
